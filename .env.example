# Public Environment Variables

ALLOWED_ORIGINS=http://localhost:4000,http://10.0.1.*:*,https://*.vercel.app,https://signal.abruno.net

# Chat Configuration
# Maximum number of previous user messages to include in context
CHAT_HISTORY_LIMIT=3

# Chroma Vector Database Configuration
CHROMA_COLLECTION=signal_knowledge
CHROMA_HOST=localhost
CHROMA_PORT=8000

# OpenRouter LLM Configuration
# Temperature setting for LLM responses (0.0-1.0)
OPENROUTER_MODEL=google/gemini-2.5-flash
OPENROUTER_TEMP=0.8

# Logging Configuration
LOG_LEVEL=debug

# MCP Configuration
MCP_SERVER_URL=http://localhost:3001
MCP_TRANSPORT=http

# Application Configuration
NODE_ENV=development

# OpenAI Configuration
# Model for generating text embeddings
OPENAI_EMBEDDING_MODEL=text-embedding-3-large

# Server Configuration
PORT=3000

# Rate Limiting Configuration
# Maximum requests per window
# Time window for rate limiting in milliseconds (1 minute)
RATE_LIMIT_MAX_REQUESTS=20
RATE_LIMIT_WINDOW_MS=60000

# RAG (Retrieval-Augmented Generation) Configuration
# Similarity threshold cutoff for retrieval
# Top K is the max number of results to retrieve
RETRIEVAL_STRONG_CUTOFF=0.2
RETRIEVAL_STRONG_TOP_K=20
RETRIEVAL_MIDDLE_CUTOFF=0.7
RETRIEVAL_MIDDLE_TOP_K=10
RETRIEVAL_WEAK_CUTOFF=0.25
RETRIEVAL_WEAK_TOP_K=25

# Private Environment Variables (API Keys)
COHERE_API_KEY=your_cohere_api_key_here
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENAI_API_KEY=your_openai_api_key_here